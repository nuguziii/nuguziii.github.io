---
title : "[Active Learning] The Power of Ensembles for Active Learning in Image Classification"
categories :
  - Paper-Review
tags :
  - Active learning
  - Deep Learning
  - Computer vision
comments : true
---

이 글은 2018 CVPR 논문, [The Power of Ensembles for Active Learning in Image Classification](https://openaccess.thecvf.com/content_cvpr_2018/papers/Beluch_The_Power_of_CVPR_2018_paper.pdf)을 참고하여 작성하였습니다.

Active learning 분야 관련 논문은 이번에 처음 읽었는데, 처음 접하시는 분들도 관련 공부하면서 읽기 좋은 논문 같아서 이렇게 글을 작성하게 되었습니다.

# Active Learning?

Active learning은 supervised learning의 특별한 케이스로, user에게 새로운 데이터에 대해서 labeling을 하게 함으로써 interactive 하게 algorithm learning을 하는 것입니다. 딥러닝에서는 주로 labeling effort를 줄이기 위해서 active learning을 사용합니다. 특히 medical image의 경우에는 굉장히 숙련된 의사들의 라벨링 작업을 요구하는 만큼 labeling cost가 상당한데, 이를 줄일 수 있는 방법입니다.

그럼 어떻게 active learning으로 labeling effort를 줄일까요? 여러가지 방법이 있겠지만, 이 논문에서는 우선 initial (라벨이 있는) small data로 학습된 모델에 라벨링이 되지 않은 새로운 data들을 넣어서 라벨링이 되어야 데이터들을 선택합니다. 한번 학습된 모델로 필터링이 되었기 때문에, 확실한 데이터 외의 라벨이 헷갈리는 데이터들만 라벨링 작업을 하면 되는거죠.

라벨링이 되어야 하는 데이터들은 **acquisition function** 을 정의해서 선택됩니다. 이 논문에서는 여러가지 acquisition function들을 비교하면서 가장 좋은 방법을 실험을 통해 보여주고 있습니다. 제목에서 볼 수 있듯이 여러 방법 중 ensemble을 이용한 방법이 가장 좋은 성능을 냈다고 합니다.

# Acquisition Function

acquisition function을 정의하는 방법에는 두가지 접근법이 있습니다. **uncertainty-based approach** 와 **geometric approach** 입니다.

## Uncertainty-Based Approach

uncertainty, 불확실성은 판단이나 의사결정에 필요한 적절한 정보의 부족으로 인해 잘못된 정보의 부족으로 이로 인해 잘못된 판단을 내릴 가능성을 말합니다. ([CURG 블로그](https://medium.com/curg/%EB%94%A5-%EB%9F%AC%EB%8B%9D%EC%97%90%EC%84%9C-dropout%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%B4-%EB%B6%88%ED%99%95%EC%8B%A4%EC%84%B1-%ED%8C%90%EB%8B%A8%ED%95%98%EA%B8%B0-14c964602ee3) 참고) active learning 에서는 라벨링 되지 않은 데이터를 모델에 넣어 라벨을 결정하는데, 이 결과가 잘못되었을 가능성을 uncertainty라고 할 수 있습니다. 그냥 softmax의 결과를 불확실성으로 그대로 이용하면 되지 않나? 라고 생각할 수 있지만, 그 값을 불확실성을 나타내지 않습니다. 학습시킨 데이터와 완전히 다른 형태의 데이터를 인풋으로 넣었을 때, 완전히 잘못된 결과를 출력하지만 softmax 값은 정확히 예측한 것처럼 나오기 때문에 이를 이용하는 것은 정확하지 않습니다.

input에 따라 다른 신경망 or weight 가 적용된다면 불확실성을 확인할 수 있는데, 기존에 Bayesian Neural Network 나 Neural Network Dropout 방법들이 있습니다. [Dropout as a Bayesian Approximation 논문](https://arxiv.org/abs/1506.02142)은 dropout regularization을 variational bayesian approximation 처럼 사용할 수 있다는 것을 보여준 논문입니다.

이러한 방법들을 논문에서는 **Monte-Carlo dropout (MC-dropout)** 방법으로 분류하고 있습니다.

또 다른 방법으로는 **Deep Ensemble** 방법이 있는데, 실제로 다른 N개의 classifier들을 이용해서 이들의 결과를 ensemble 하는 것입니다.

MC-dropout 또는 Deep Ensemble로 얻은 output을 이용하여 uncertainty를 예측하는 방법들로 (1)[entropy](https://ieeexplore.ieee.org/document/6773024), (2)[BALD](https://arxiv.org/abs/1112.5745), (3)[variation ratio](https://arxiv.org/abs/1703.02910) 이 있습니다.

## Geometric Approach

geometric approach는 model로 생성된 representation field를 이용하여 uncertainty를 예측하는 방법입니다. 이 논문에서는 비교평가를 위해 [Core-Set](https://arxiv.org/abs/1708.00489), [REPR](https://arxiv.org/abs/1706.04737) 방법들을 사용하였습니다.

# Results

MC-dropout / Deep Ensemble + entropy / BALD / variation ratio 를 조합한 6가지 방법들과 geometric approach Core-Set, REPR 을 비교한 결과 Deep Ensemble + variation ratio 방법이 가장 좋다는 것이 이 논문의 결론입니다. 자세한 비교평가는 논문을 참고하시면 될 것 같습니다.

흥미로운 실험 중 하나가 medical dataset에 적용하여서 healthy/unhealthy binary classification task를 수행하는 것이었는데, 확실히 위 방법인 Ens-VarR이 결과가 좋은 것을 보여주었습니다. acquisition step에 따라 labeling 을 요청하는 unhealthy 이미지 개수를 차트에서 보여주었는데, Ens-VarR이 다른 방법에 비해 압도적으로 많은 unhealthy 이미지의 classification을 요청하였습니다.
