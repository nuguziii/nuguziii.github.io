---
title : "[논문읽기] Noise2Noise: Learning Image Restoration without Clean Data"
categories :
  - Paper Review
tags :
  - Vision
comments : true
---
이 글은 2018 ICML 논문, [Noise2Noise: Learning Image Restoration without Clean Data](https://arxiv.org/pdf/1803.04189.pdf)와 [TechTalksTV 영상](https://vimeo.com/287807759)을 참고하여 작성하였습니다.

이 논문은 작년에 발표되었던 논문이지만, 읽었을 당시 매우 인상깊어서 꼭 블로그 글로 작성해보고 싶었습니다. Image Denoising 주제에 대해 관심이 많았었는데, 기존 논문들과 다른 방식으로 접근했던 점이 인상깊었습니다. 대부분의 Image Denoising Task 들은 supervised learning 으로 clean한 영상을 학습하기 위해서 noisy 영상과 original 영상을 모두 필요로 합니다. 하지만, 이 논문에서는 약간 다른 방법을 씁니다. 오로지 noisy한 영상만으로 clean한 영상을 뽑아내죠. clean한 영상이 없을 경우에 고민할 필요가 없어졌습니다.

논문에도 다음과 같이 적혀있습니다.
> "learn to turn bad images into good images by only looking at bad images"

그럼 한번 Noise2Noise 논문 리뷰 시작해보도록 하겠습니다:)

## Background

일반적인 Image Denoising Task에서 식은 다음과 같습니다.

$$
\arg\min\sum_{i}L(f_\theta(\hat{x_i}), y_i)
$$

$$\hat{x_i}$$는 corrupted image (noisy image)이고, $$y_i$$는 clean image (target)입니다. 둘 사이에 Loss Function (L1 또는 L2)을 통해 차이를 minimize 시키고, noise가 제거되도록 학습됩니다. 대표적으로 [DnCNN](https://arxiv.org/abs/1608.03981) 논문에서 이러한 방식을 씁니다. (다만, DnCNN에서는 $$f_\theta(\hat{x_i})$$ 값이 denoised image가 아닌 residual이니 noisy image에서 빼줘야합니다) 하지만, 이러한 방법으로 학습하기 위해서는 항상 Clean Image를 필요로 합니다. Clean training target들을 얻는 것은 때론 어렵거나 cost가 큽니다. (ex. long exposure)

또한, 논문에서는 L1/L2 Loss에 대해서도 자세히 설명을 하고 있습니다. L1 Loss는 median값을 추정하고, L2 Loss는 mean 값을 추정합니다. (이유에 대해서는 [여기](https://stats.stackexchange.com/questions/34613/l1-regression-estimates-median-whereas-l2-regression-estimates-mean)에 수학적/직관적인 여러 설명들이 있습니다.) Image Denoising을 할 때를 생각해보면, 보통 input과 target간의 1:1 mapping이 아니고, target이 될 수 있는 것은 여러가지 입니다.(noisy image에서 노이즈를 제거했을 때 나오는 최적의 clean image는 하나만 있을수가 없습니다) 따라서, 여기에 L2 Loss를 적용한다면 네트워크는 모든 가능한 target의 경우를 평균낸 결과를 학습하고, 결과에 blurriness 효과가 있을 수 밖에 없습니다. (perceptual loss를 쓰는 이유)

## Methods
이 논문에서는 L2 Loss가 모든 가능한 target의 경우를 평균낸다는 점을 이용합니다. 모든 가능한 경우를 평균낸 최적의 output z (denoised image)를 식으로 나타내면 다음과 같습니다.

$$
z = \mathbb{E_y}\{y\}
$$

하지만, 이때 y가 항상 clean image일 필요는 없습니다. 각 y가 random numbers여도 expectation만 target과 일치한다면 같은 방법으로 최적의 z를 찾을 수 있겠죠. 바로 이것이 논문이 제안한 방법입니다.

> This implies that we can, in principle, corrupt the training targets of a neural newtork with zero-mean noise without changing what the network learns

식을 이제는 이렇게 쓸 수 있습니다.

$$
\arg\min\sum_{i}L(f_\theta(\hat{x_i}), \hat{y_i})
$$

x와 y가 모두 corrupted image가 되는 것이죠.

![캡처](https://i.imgur.com/Oreaq8x.png)

다음 그림으로도 논문의 방법을 설명할 수 있습니다. 이 그림은 저자의 발표 영상에서 가져온 것입니다. 왼쪽이 원래 기존에 많이 하는 방법, 오른쪽이 논문에서 제안한 방법입니다. Averge gradient를 통해 주위의 noisy target으로 부터 clean target을 얻게 되는 것을 보여줍니다.

## Experiments

논문에서는 gaussian noise, synthesis noise, Monte Carlo Rendering, MRI 등의 noise removal에 대한 실험 결과를 보여주고 있습니다. 다음 그림도 논문 실험결과의 일부인데요, 더 자세한 training detail, result 등은 [논문](https://arxiv.org/pdf/1803.04189.pdf)을 참고하면 좋을 것 같습니다.

![캡처](https://i.imgur.com/AHgJmI4.png)

---
<p style="font-size:14px; color:gray;">
읽었을 당시에는 몰랐는데 리뷰하면서 보니 또 NVIDIA 논문이었네요.:o 직관적으로는 알겠는데, 수학적으로 이해하려니 조금 어려움이 있었던 논문이었습니다. (수학 공부를 더 열심히...) 다음에 기회가 된다면 이 논문에 영감을 받아서 나온 올해 CVPR논문 [Noise2Void](https://arxiv.org/pdf/1811.10980.pdf)도 리뷰해보도록 하겠습니다.
</p>

**Reference**:<br>
[1] [Noise2Noise paper](https://arxiv.org/pdf/1803.04189.pdf)<br>
[2] [Noise2Noise github](https://github.com/NVlabs/noise2noise#noise2noise-learning-image-restoration-without-clean-data---official-tensorflow-implementation-of-the-icml-2018-paper)
