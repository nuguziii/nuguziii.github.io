---
title : "[세미나 후기] Reducing Annotation Cost in Medical Image Analysis (by Lunit)"
categories :
  - 후기
tags :
  - medical
  - ai
comments : true
---
오늘 학교에 Lunit의 유동근 연구소장님께서 오셔서 **"Reducing Annotation Cost in Medical Image Analysis"** 관련 세미나를 하셨습니다. 의료 ai에 관심이 많았던 만큼 열심히 들었고, 최신 트랜드를 반영한 연구 전반적인 내용에 대해 짚어주시며 좋은 논문들을 소개해주셔서 좋았습니다. 이에 관련하여 후기 및 세미나에서 소개한 논문들 간단리뷰를 해볼까 합니다.

## Introduction

딥러닝에서 모델을 학습시키기 위해 가장 중요한 것은 **데이터** 입니다. 수가 많을 수록 좋고, 깨끗한 데이터일 수록 좋습니다. 보통 supervised learning의 경우에는 많은 양의 input data와 output data 쌍을 필요로 합니다. (이 [논문](http://openaccess.thecvf.com/content_ECCV_2018/papers/Dhruv_Mahajan_Exploring_the_Limits_ECCV_2018_paper.pdf)에서 무조건적으로 데이터가 많을 수록 학습이 잘된다는 것을 보여줍니다.)

일반 영상인 경우에도 많은 양의 데이터를 구하는 것이 힘들지만, **medical** 영상의 경우 더욱 문제입니다. input data의 annotation을 구하는데 cost가 매우 크다는 문제입니다. 전문가들을 필요로 하는 부분이기 때문이죠.

따라서, Lunit에서는 이러한 annotation cost를 줄이기 위해 다음 세 가지 관점에서 접근하고 있다고 합니다.

> 1.  Choose important data to annotate
> 2.  Cheap and Scalable Annotation
> 3.  Generalize within-domain annotation

이것들을 구체적으로 설명하기 전에, 최종적으로 어떤 것들을 위해 이러한 연구를 하는지 설명하도록 하겠습니다.

#### - Why? 어떤 목표를 위해 연구를 하는가

의료 ai의 경우 2가지 목표를 갖고 연구와 개발을 하고 있다고 합니다.
> 1. 암 진단을 더욱 초기에 정확하게 할 수 있는 기술
> 2. 환자의 암 상태에 필요한 약을 찾아주는 기술

우선 암진단 관련해서는 굉장히 흥미로운 결과들을 많이 보여주셨는데요, 이미 Lunit으로 진단한 결과가 전문가가 진단한 정확도보다 더 높고, Lunit의 도움을 받으면 정확도가 훨씬 높아지는 것을 보여주셨습니다. 또한, 전문가들은 발견하지 못했던 초기 암도 lunit은 발견하는 경우도 있었습니다.

[Lunit insight](https://insight.lunit.io/) 에 들어가면 직접 x-ray 영상을 갖고 데모를 해볼 수 있다고 합니다.

환자의 암에 필요한 약을 찾아주는 기술 역시 과정이 굉장히 흥미로웠습니다. 일단, 암세포 영상을 자동으로 분석하여 암세포가 몇개 있는지, 비율 정보, 조직 모양 등을 quantification(정량화) 합니다. 그 후에 이 정량화 정보를 모델에 넣어 어떠한 약이 효과가 있을지 예측하는 것입니다.

아래는 이렇게 분석해주는 툴, [Lunit Scope](https://scope.lunit.io/app)의 일부를 캡처한 것입니다.

![스크린샷 2019-11-29 오전 1.41.33](https://i.imgur.com/NsxCJLh.jpg)

## Reducing Annotation Cost

앞에서 세 가지 방면으로 annotation cost를 줄이고 있다고 했습니다. 이것들은 각각 Active learning, Weakly supervised learning, Domain generalization 방법들로 접근하여 연구를 하고 있다고 합니다. (이 부분에는 개인적인 논문 리뷰 내용도 포함되어 있습니다.)

> 1.  Choose important data to annotate -> Active learning
> 2.  Cheap and Scalable Annotation -> Weakly supervised learning
> 3.  Generalize within-domain annotation -> Domain generalization

#### 1. Active learning

"Annotation을 해줘야 하는 데이터만 annotation을 하자"라는 취지에서 active learning을 활용하게 되었다고 합니다. Active learning을 이용하여 ai 입장에서 어떤 데이터들이 labeling 하기 어려운지 (uncertainty)를 판별하고, 만약 uncertain 하다면, 전문가의 도움으로 labeling 한 다음에 이 데이터들을 다시 ai 모델에 학습시킴으로서 더 나아가는 것입니다.

Active learning 관련 논문으로는 2019 CVPR oral 발표 논문인,"[Learning Loss for Active Learning](https://arxiv.org/abs/1905.03677)"을 소개하셨습니다. 이 논문에서는 Task-specific하고 scalable 하지 않았던 기존 연구들의 한계점을 보완했다고 합니다.

> "Task-agnostic, Learning-based, Scalable"

![adasd](https://i.imgur.com/woquCq9.png)

논문에서 제안한 구조는 위 그림과 같습니다. Loss prediction module을 두어서, input data가 들어오면 loss를 예측할 수 있도록 학습이 됩니다. 후에 이 Loss prediction module을 통해서 labeling uncertainty를 측정할 수 있는 것이죠. (loss가 클수록 uncertainty가 크므로) 더 자세한 내용은 [논문](https://arxiv.org/abs/1905.03677)을 참고하면 좋을 것 같습니다.

#### 2. Weakly supervised learning

annotation cost를 줄이기 위해, annotation을 너무 정교하게 "잘" 하는 것은 시간과 비용이 많이 드니, 대충 annotation 해도 잘 학습될 수 있도록 하자! 해서 나온 것이 weakly supervised learning 이라고 합니다. 여기서 대충 annotation이라는 것은 Scribble이나 point로 annotation을 하는 것을 의미합니다.

관련해서는 2019 MICCAI 논문, "[PseudoEdgeNet: Nuclei Segmentation only with Point Annotation](https://arxiv.org/pdf/1906.02924.pdf)" 을 소개하셨습니다. 이 논문은 image와 point만을 이용하여 segmentation을 하는 것입니다.

> **Weakly supervised** **nuclei segmentation** method, which requires only **point annotations** for training.

![asdss](https://i.imgur.com/dCNX4Xv.png)

위 그림은 이 논문에서 제안한 네트워크 구조입니다. 일단 segmentation network f가 있고, point 만으로 segmentation loss를 구하면 부정확할 수 있기 때문에 PseudoEdgeNet (edge net g, attention module h)를 추가로 사용한다고 합니다.

point annotation을 정할때, 기존 point pixel, positive label과 Voronoi boundaries에 있는 pixel, negative label로 정의한다고 합니다. 이 point annotation P를 이용하여 segmentation net f와 Edge net G가 jointly learned 됩니다. edge net의 정답은 segmentation net에서 나온 결과에 sobel filter를 적용한 것입니다.

이 edge net과 segmentation net으로도 명확한 성능을 보이긴 하지만, edge의 퀄리티를 더 높이기 위하여 attention module을 적용하였습니다. edge network가 작아서 semantic 적인 요소를 고려하지 않고 무관한 배경에서도 edge들을 뽑아내는 경우가 많은데, 이를 줄이기 위해 어떤 부분의 edge를 추출해야하는지 high-level에서 알려줍니다.

이러한 방법을 이용하여 nuclei segmentation 부분에서는 최초로 weakly-supervised를 적용한 논문이라고 합니다.

#### 3. Domain generalization

만약 서울대 병원 데이터만 갖고 모델을 만들어서 멕시코 병원에 적용하려고 하면 여러 문제가 있다고 합니다. 인종, 의료장비 등이 다르기 때문에 서울대 병원에서만큼의 성능이 나오지 않는다고 합니다. 하지만, 실제 real-world distribution을 얻기는 어렵고, 우리는 이때, domain generalization을 필요로 합니다.

주어진 labeled 데이터셋을 갖고 모델을 학습하는데, unknown domain에도 적용시킬 수 있을 만큼 invariant하게 하는 것입니다. 관련 논문으로 2018 NIPS 논문, "[Batch-Instance Normalization for Adaptively Style-Invariant Neural Networks](https://arxiv.org/pdf/1805.07925.pdf)"를 소개하셨습니다.

이 논문에서는 Batch-Instance Normalization (BIN)을 이미지의 불필요한 스타일들을 제거하였습니다. 간단하게, feature stat에서 domain style 정보는 날리고, classification style 정보만 남김으로써 domain generalization을 가능하게 하는 것이죠. style transfer가 이렇게 domain generalization에 이용될 수 있을 줄은 예상하지 못해서 굉장히 흥미롭게 읽을 수 있었던 논문입니다.

논문에 대한 자세한 설명은 [Lunit Tech Blog](https://blog.lunit.io/2018/05/25/batch-instance-normalization/)를 참고하면 좋을 것 같습니다.

## Domain Adaptation

마지막으로, 이번 ICCV 2019 Visual Domain Adaptation Challenge에서 1등을 한 lunit 논문 "[Reducing Domain Gap via Style-Agnostic Networks](https://arxiv.org/pdf/1910.11645.pdf)" 를 소개해주셨습니다.

이때 사용한 한가지 방법으로 style adversarial learning을 설명해주셨습니다. 굉장히 간단한 아이디어인데, 효과적으로 작용한 것이 흥미로웠던 방법이었습니다. gradient reversal 해서 style이 제거되도록 하는 방법이었습니다.

대략적인 네트워크 구조는 아래와 같습니다.

![sfsdfsf](https://i.imgur.com/Hac1sCD.png)

## 마무리

그동안 Lunit에서 해왔던 멋진 연구들을 소개해주셔서 최근 들었던 세미나 중 가장 유익한 시간이었습니다. 무엇보다도 제가 기존에 읽어왔던 Knowledge Distillation, Low-level vision와 다른 새로운 분야들의 연구를 배울 수 있어서 좋았습니다. 이번 ICCV 에서도 Domain Adaption 관련해서 매우 많은 논문이 나왔고, 많은 사람들에 이에 관심을 갖고 있었다는 사실을 알게되었는데, 이번 세미나를 통해 또다시 중요성을 느끼게 되었습니다.

특히, Style transfer 개념이 domain adaptation에도 쓰인다는 것을 이 세미나를 통해 처음 알게되었고, 간단한 아이디어로 좋은 결과를 낸 연구들이 많아서 매우 흥미로웠습니다.

앞으로는 Limited Data, Domain Adaptation 등의 annotation cost를 줄일 수 있는 방법에 대한 논문도 많이 읽고 리뷰해봐야겠습니다:)
